# “Ethics, Public Policy and Technology Change” course notes

> **If we want a more ethically informed technology industry today,\
> we need an ethical study for technology professionals, not just college students.**\
> — [Lisa Wehden](https://techcrunch.com/2020/04/24/silicon-valley-needs-a-new-approach-to-studying-ethics-now-more-than-ever/)

Collected notes, links, and personal musings from the 2-month evening course on ethics in technology for working professionals from Stanford and Bloomberg Beta. 

### Table of contents
1. [February 3, 2021: Opening session](https://github.com/skullface/ethics-notes/blob/main/README.md#3-feb-opening-session)
2. [February 10, 2021: Privacy and digital civil liberties](https://github.com/skullface/ethics-notes#10-feb-privacy-and-digital-civil-liberties)
3. Februrary 17, 2021
4. February 24, 2021
5. March 3, 2021
6. March 10, 2021
7. March 17, 2021

---

<details>
  <summary>Course description</summary>

> **Evening course with Stanford professors and Bloomberg Beta (Feb–March 2021)**
>
> Over the course of seven weeks, admitted students will study with three Stanford professors and a curated group of technologists, public officials, civil society leaders, and scholars in conversation around ethics, public policy, and technological change.
>
> The focus: discuss multiple, often opposing, views about what can and should be done around the ethical and social issues technology companies face. We’ll look at fundamental texts, and explore them in the context of issues like; obligations to community and society, data privacy, algorithmic decision-making, handling contractors vs. employees, geopolitics, the power of private platforms, diversity and inclusion, and the culture of Silicon Valley.

</details>

---

## 3 Feb: Opening session

As a group of technology professionals who care about ethics, we are not trying to find a utopia that can’t exist — but not having a perfect answer to our thorny problems is not an excuse to throw up our hands and do nothing. “**_Complicity is the resting state of adulthood._**” Learning, thinking, and engaging in discussions about ethics should be morally ”caffeinating“, stimulating for future action.

### Reading discussion

* Le Guin, Ursula K. “[The Ones Who Walk Away from Omelas](https://en.wikipedia.org/wiki/The_Ones_Who_Walk_Away_from_Omelas).” 1973.

We approach this not from a utilitarian context (i.e., the trolley problem, *The Good Place*) as it is traditionally considered, but within the context of our industry. Are “the ones who walk away from Omelas” heroes or cowards? Are those who stay and advocate for better “activists”? What about choosing the dictitatorial path to free the child yourself? Can anyone actually walk away? What are we walking away from?

Consider rejecting the premise of the question before even considering your answer to the question.

You should lose sleep at night when you hesitate between answering what you *should* do and what you *would* do.

##### Further reading

* Kristof, Nicholas. “[We Are a Nation of Child Abusers.](https://www.nytimes.com/2021/02/03/opinion/biden-child-poverty.html)” *The New York Times*, 3 Feb 2021.
* James, William. “[The Moral Philosopher and the Moral Life.](https://en.wikipedia.org/wiki/The_Moral_Philosopher_and_the_Moral_Life)” *The Will to Believe and Other Essays in Popular Philosophy: Human Immortality*, 1956, p. 185.
* Hirschman, Albert O. [*Exit, Voice, and Loyalty: Responses to Decline in Firms, Organizations, and States*](https://en.wikipedia.org/wiki/Exit,_Voice,_and_Loyalty). 2007.

## 10 Feb: Privacy and digital civil liberties

### What is privacy?

* Aristotle: the public sphere (politics and commerce, for men) X the private sphere (domestic life, family and friends, the realm of women)
  * Individuals have interests in shielding the public from seeing/hearing what happens in private

* Contemporarily, **social context is what's important**, in public or in private (Nissenbaum).
  * We want to be able to control what is known about us, how we present ourselves, whether we are in public or private spaces. 
  * Privacy is central to individual autonomy or self-determination

* The modern philosophical defintion of privacy: **the claim of indvidiauls to determine for themselves when, how, and to what extent information about them is shared with or communicated to others** 
  * Violations of privacy impose harms
  * Protecting intimacy, freedom, and control

#### Privacy harms (Solove, “A taxonomy of privacy”)

1. Information collection (surveillance)
2. Information processing (aggregation and inferences from big data)
3. Information dissemination (breach of confidentialty, discloure third parties, blackmail)
4. Invasion of privacy (intrusion, decision interference)

#### Rival values

What other values (or rights, or interests) might be in tension with privacy (however we construe it)?

1. National security (terrorism)
2. Public safety (crime)
3. Innovation
4. Convenience

### Notice and consent

Generally the U.S. approach to data held by companies is based on a combination of **transparency and choice**. 

U.S. entities inform individuals of their respective information-flow practices and providep eople with a choice to consent or not.

This approach has a broad appeal given:

1. Our conception of privacy as the right to control information about oneself2
2. Our commitment to notions of a competitive free market, in which people can go elsewhere if they don't like the terms.

For the current light-touch approach to privacy regulation to work, three things msut be true:

1. Individuals must be able to make informed, rational choices about the costs and benefits of different privacy policies
2. The market must be able to deliver a diversity of products with different privacy settings
3. We must be able to achive the societal balance that we want between privacy and other values via a set of decentralized decisions

…Are these things true in practice?

Are individuals up to the challenge of navigating privacy in the information age?

Social scientists are skeptical (Acquisti 2015). Lawyers are concerned (Solove 2013). Information scientists doubt it (Nissenbaum 2011). Why?

1. People are uncertain about their preferences
2. Pereferences are context-dependent
3. Privacy prefs can be manipulated
4. Privacy self-management does not scale well
5. People cannot factor in aggregation
6. People cannot anticipate harm

#### Alternatives?

Comprehensive privacy regulation, but:

* This denies people the freedom to make choices
* It's not always clear how to trade off privacy and data use
* There are social benefits to data aggregation

Improving privacy self-management through:

* Opt-in consent rather than opt-out consent
* Managing privacy globally rather than locally
* Focusing on downstream use
* Codify basic privacy norms about what is not acceptable

### Perspectives on data privacy

* Data privacy often involves a balance of competing interests
* Making data available for meaningful analysis
  * for public good: medical research and healthcare improvement, protecting national security
  * for private good: personalized advertising
* Deleting identifiers doesn't make data unidentifiable

### Why do _I_ care about protecting my own privacy?

- I'm an outspoken woman on the Internet and that comes with a cost. I need to protect myself and my family from any potential abuse.
- I don't want to be treated differently because of my lifestyle, like where I live. 
- I don't want to be discriminated against based on what I don't know about. 
- I'm going to live for a while — I want to be in charge of what exists in the future for my self, my family, and my children.
- I want to be able to act freely.
- I want to be able to protest against my country and my government without fear for my safety.
- I want to be able to make my own decisions without the influence of microtargeting.
- I work for a visible, prominent company, so bad actors might want to do harm to gain access to internal info, which could jeapordize my employment.

### Reading list

* Solove, Daniel. “[‘I’ve Got Nothing to Hide’ and Other Misunderstandings of Privacy](https://digital.sandiego.edu/sdlr/vol44/iss4/5/).” San Diego Law Review, vol. 44, 12 Jul 2007, p. 745.
* Acquisti, Alessandro; Brandimarte, Laura; Loewenstein, George. “[Privacy and Human Behavior in the Age of Information](https://science.sciencemag.org/content/347/6221/509.long).” Science, vol. 347, no. 6221, 30 Jan. 2015, pp. 509–514. 
* Hill, Kashmir. “[The Secretive Company That Might End Privacy as We Know It](https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html).” *The New York Times*, 18 Jan. 2020. 
* Green, Matthew. “[What is Differential Privacy?](https://blog.cryptographyengineering.com/2016/06/15/what-is-differential-privacy/)” *A Few Thoughts on Cryptographic Engineering*, 15 June 2016.

### Further reading

TK
