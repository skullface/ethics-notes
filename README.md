# ‚ÄúEthics, Public Policy and Technology Change‚Äù course notes

> **If we want a more ethically informed technology industry today,\
> we need an ethical study for technology professionals, not just college students.**\
> ‚Äî [Lisa Wehden](https://techcrunch.com/2020/04/24/silicon-valley-needs-a-new-approach-to-studying-ethics-now-more-than-ever/)

Collected notes, links, and personal musings from the 2-month evening course on ethics in technology for working professionals from Stanford and Bloomberg Beta. 

### Table of contents
1. [February 3, 2021: Opening session](https://github.com/skullface/ethics-notes/blob/main/README.md#3-feb-opening-session)
2. [February 10, 2021: Privacy and digital civil liberties](https://github.com/skullface/ethics-notes#10-feb-data-collection-privacy-and-digital-civil-liberties)
3. Februrary 17, 2021
4. February 24, 2021
5. March 3, 2021
6. March 10, 2021
7. March 17, 2021

---

<details>
  <summary>Course description</summary>

> **Evening course with Stanford professors and Bloomberg Beta (Feb‚ÄìMarch 2021)**
>
> Over the course of seven weeks, admitted students will study with three Stanford professors and a curated group of technologists, public officials, civil society leaders, and scholars in conversation around ethics, public policy, and technological change.
>
> The focus: discuss multiple, often opposing, views about what can and should be done around the ethical and social issues technology companies face. We‚Äôll look at fundamental texts, and explore them in the context of issues like; obligations to community and society, data privacy, algorithmic decision-making, handling contractors vs. employees, geopolitics, the power of private platforms, diversity and inclusion, and the culture of Silicon Valley.

</details>

---

## 3 Feb: Opening session

As a group of technology professionals who care about ethics, we are not trying to find a utopia that can‚Äôt exist ‚Äî but not having a perfect answer to our thorny problems is not an excuse to throw up our hands and do nothing. ‚Äú**_Complicity is the resting state of adulthood._**‚Äù Learning, thinking, and engaging in discussions about ethics should be morally ‚Äùcaffeinating‚Äú, stimulating for future action.

### Reading discussion

* Le Guin, Ursula K. ‚Äú[The Ones Who Walk Away from Omelas](https://en.wikipedia.org/wiki/The_Ones_Who_Walk_Away_from_Omelas).‚Äù 1973.

We approach this not from a utilitarian context (i.e., the trolley problem, *The Good Place*) as it is traditionally considered, but within the context of our industry. Are ‚Äúthe ones who walk away from Omelas‚Äù heroes or cowards? Are those who stay and advocate for better ‚Äúactivists‚Äù? What about choosing the dictitatorial path to free the child yourself? Can anyone actually walk away? What are we walking away from?

Consider rejecting the premise of the question before even considering your answer to the question.

You should lose sleep at night when you hesitate between answering what you *should* do and what you *would* do.

##### Further reading

* Kristof, Nicholas. ‚Äú[We Are a Nation of Child Abusers.](https://www.nytimes.com/2021/02/03/opinion/biden-child-poverty.html)‚Äù *The New York Times*, 3 Feb 2021.
* James, William. ‚Äú[The Moral Philosopher and the Moral Life.](https://en.wikipedia.org/wiki/The_Moral_Philosopher_and_the_Moral_Life)‚Äù *The Will to Believe and Other Essays in Popular Philosophy: Human Immortality*, 1956, p. 185.
* Hirschman, Albert O. [*Exit, Voice, and Loyalty: Responses to Decline in Firms, Organizations, and States*](https://en.wikipedia.org/wiki/Exit,_Voice,_and_Loyalty). 2007.

## 10 Feb: Data collection, privacy and digital civil liberties

### Focuses
* Changing norms and laws around privacy across time and cultures, including how people balance privacy vs. other goals
* Data aggregation, matching, and de-anonymization strategies
* Facial recognition technology (used by public and private actors)
* Consent for different types and uses of data

### What is privacy?

* Aristotle: public sphere (politics and commerce üöπ) differs from private sphere (domestic life, family and friends üö∫)
  * Individuals have interests in shielding the public from what happens in private

* Social context is key, regardless of being in public or private
  * We want to be able to control what is known about us + how we present ourselves
  * Privacy is central to individual autonomy or self-determination

* Modern, philosophical defintion of privacy:
  > **The claim of individuals to determine for themselves when, how, and to what extent information about them is shared with or communicated to others**\
  > _Privacy and Freedom_, by Alan F. Westin, Atheneum, 1970, p. 7. 
  * Violations of privacy impose harms
  * Privacy is about protecting intimacy, freedom, and control (Solove, ‚Äú‚ÄòI‚Äôve Got Nothing to Hide‚Äô‚Äù)

#### Privacy harms
Solove, Daniel J. ‚Äú[A Taxonomy of Privacy](https://www.jstor.org/stable/40041279?seq=1).‚Äù University of Pennsylvania Law Review, vol. 154, no. 3, 2006, p. 477.

1. Information collection (surveillance)
2. Information processing (aggregation and inferences from big data)
3. Information dissemination (breach of confidentialty, discloure third parties, blackmail)
4. Invasion of privacy (intrusion, decision interference)

#### Rival values

What other values/rights/interests might be in tension with privacy?

1. National security (terrorism)
2. Public safety (crime)
3. Innovation
4. Convenience

#### Notice and consent

* U.S. approach to a company‚Äôs data: transparency and choice 
* U.S. entities inform individuals and provide a choice to consent or not
* ‚Ä¶This is appealing because 
  1. our idea of privacy is to control information about ourselves
  2. we are committed to the idea of a free market
* But that‚Äôs only true if‚Ä¶
  1. Individuals must be able to make informed, rational choices about the costs and benefits of different privacy policies
  2. The market must be able to deliver a diversity of products with different privacy settings
  3. We must be able to achive the societal balance that we want between privacy and other values via a set of decentralized decisions
* ‚Ä¶Are those true in practice?
* Are individuals today actually up to the challenge of navigating privacy?
  * Social scientists are skeptical (Acquisti 2015). Lawyers are concerned (Solove 2013). Information scientists doubt it (Nissenbaum 2011).
    1. People are uncertain about their preferences
    2. Pereferences are context-dependent
    3. Privacy prefs can be manipulated
    4. Privacy self-management does not scale well
    5. People cannot factor in aggregation
    6. People cannot anticipate harm

#### What are the alternatives?

* Comprehensive privacy regulation
  * ‚Ä¶denies people the freedom to make choices
  * ‚Ä¶is not always clear in the trade off of privacy vs. data use
  * ‚Ä¶limits social benefits to data aggregation
* Improving privacy self-management through:
  * Opt-in > opt-out consent
  * Global > local management
  * Focus on downstream use
  * Acceptability of basic privacy norms

#### Perspectives on data privacy

* Data privacy often involves a balance of competing interests
* Making data available for meaningful analysis
  * for public good: medical research and healthcare improvement, protecting national security
  * for private good: personalized advertising
* Deleting identifiers doesn‚Äôt make PII unidentifiable

### Why do _I_ care about protecting my own privacy?

- I‚Äôm an outspoken woman on the Internet and that comes with a cost. I need to protect myself and my family from any potential abuse.
- I don‚Äôt want to be discriminated against based on criteria I don‚Äôt know about. 
- I‚Äôm going to live for a while ‚Äî I want to be in charge of what information about me exists in the future for my self, my family, and my children.
- I want to be able to protest against my country and my government without fear for my safety.
- I don‚Äôt want to be treated differently because of lifestyle choices I intend to keep private.
- I want to be able to make my own decisions without the influence of microtargeting.
- I work for a visible, prominent company, and bad actors could weaponize that against me based on information I intend to keep private.

### Reading list

* Solove, Daniel. ‚Äú[‚ÄòI‚Äôve Got Nothing to Hide‚Äô and Other Misunderstandings of Privacy](https://digital.sandiego.edu/sdlr/vol44/iss4/5/).‚Äù San Diego Law Review, vol. 44, 12 Jul 2007, p. 745.
* Acquisti, Alessandro; Brandimarte, Laura; Loewenstein, George. ‚Äú[Privacy and Human Behavior in the Age of Information](https://science.sciencemag.org/content/347/6221/509.long).‚Äù Science, vol. 347, no. 6221, 30 Jan. 2015, pp. 509‚Äì514. 
* Hill, Kashmir. ‚Äú[The Secretive Company That Might End Privacy as We Know It](https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html).‚Äù *The New York Times*, 18 Jan. 2020. 
* Green, Matthew. ‚Äú[What is Differential Privacy?](https://blog.cryptographyengineering.com/2016/06/15/what-is-differential-privacy/)‚Äù *A Few Thoughts on Cryptographic Engineering*, 15 June 2016.

### Further reading

TK
