# ‚ÄúEthics, Public Policy and Technology Change‚Äù course&nbsp;notes

> **If we want a more ethically informed technology industry today,\
> we need an ethical study for technology professionals, not just college students.**\
> ‚Äî [Lisa Wehden](https://techcrunch.com/2020/04/24/silicon-valley-needs-a-new-approach-to-studying-ethics-now-more-than-ever/)

Collected notes, links, and personal musings from the 2-month evening course on ethics in technology for working professionals from Stanford and Bloomberg Beta. 

### Table of contents
1. [February 3, 2021: Opening session](https://github.com/skullface/ethics-notes/blob/main/README.md#3-feb-opening-session)
2. [February 10, 2021: Privacy and digital civil liberties](https://github.com/skullface/ethics-notes#10-feb-data-collection-privacy-and-digital-civil-liberties)
3. [Februrary 17, 2021: Platforms and the public sphere](https://github.com/skullface/ethics-notes#17-feb-platforms-and-the-public-sphere)
4. February 24, 2021
5. March 3, 2021
6. March 10, 2021
7. March 17, 2021

---

<details>
  <summary>Course description</summary>

> **Evening course with Stanford professors and Bloomberg Beta (Feb‚ÄìMarch 2021)**
>
> Over the course of seven weeks, admitted students will study with three Stanford professors and a curated group of technologists, public officials, civil society leaders, and scholars in conversation around ethics, public policy, and technological change.
>
> The focus: discuss multiple, often opposing, views about what can and should be done around the ethical and social issues technology companies face. We‚Äôll look at fundamental texts, and explore them in the context of issues like; obligations to community and society, data privacy, algorithmic decision-making, handling contractors vs. employees, geopolitics, the power of private platforms, diversity and inclusion, and the culture of Silicon Valley.

</details>

---

## 3 Feb: Opening session

As a group of technology professionals who care about ethics, we are not trying to find a utopia that can‚Äôt exist ‚Äî but not having a perfect answer to our thorny problems is not an excuse to throw up our hands and do nothing. ‚Äú**_Complicity is the resting state of adulthood._**‚Äù Learning, thinking, and engaging in discussions about ethics should be morally ‚Äùcaffeinating‚Äú, stimulating for future action.

### Reading discussion

- Le Guin, Ursula K. ‚Äú[The Ones Who Walk Away from Omelas](https://en.wikipedia.org/wiki/The_Ones_Who_Walk_Away_from_Omelas).‚Äù 1973.

We approach this not from a utilitarian context (i.e., the trolley problem, _The Good Place_) as it is traditionally considered, but within the context of our industry. Are ‚Äúthe ones who walk away from Omelas‚Äù heroes or cowards? Are those who stay and advocate for better ‚Äúactivists‚Äù? What about choosing the dictitatorial path to free the child yourself? Can anyone actually walk away? What are we walking away from?

Consider rejecting the premise of the question before even considering your answer to the question.

You should lose sleep at night when you hesitate between answering what you _should_ do and what you _would_ do.

<details>
  <summary><strong>Supplementary reading</strong></summary>

- Kristof, Nicholas. ‚Äú[We Are a Nation of Child Abusers.](https://www.nytimes.com/2021/02/03/opinion/biden-child-poverty.html)‚Äù _The New York Times_, 3 Feb 2021.
- James, William. ‚Äú[The Moral Philosopher and the Moral Life.](https://en.wikipedia.org/wiki/The_Moral_Philosopher_and_the_Moral_Life)‚Äù _The Will to Believe and Other Essays in Popular Philosophy: Human Immortality_, 1956, p. 185.
- Hirschman, Albert O. [_Exit, Voice, and Loyalty: Responses to Decline in Firms, Organizations, and States_](https://en.wikipedia.org/wiki/Exit,_Voice,_and_Loyalty). 2007.
- ‚Äú[Two Cultures](http://s-f-walker.org.uk/pubsebooks/2cultures/Rede-lecture-2-cultures.pdf&sa=D&source=editors&ust=1613277808145000&usg=AOvVaw3ON4tTEABjgjLdYIBkAUsn)‚Äù by C. P. Snow (The Rede Lecture, 1959)
- ‚Äú[Feynman‚Äôs Error: On Ethical Thinking and Drifting](https://www.danmunro.ca/blog/2018/11/29/feynmans-error-on-ethical-thinking-and-drifting-nbsp&sa=D&source=editors&ust=1613277808144000&usg=AOvVaw1MOhlv-gfnpOes05VOwKnY)‚Äù by Dan Munro (Dan‚Äôs blog, November 2018)
- ‚Äú[Optimize What?](https://communemag.com/optimize-what/&sa=D&source=editors&ust=1613277808144000&usg=AOvVaw1FFqY5YRKjqgx_vGiunzPw)" by Jimmy Wu
- ‚Äú[Solving for Pattern](http://ceadserv1.nku.edu/longa/haiti/kids/history/Berry_Solving_for_Pattern.pdf&sa=D&source=editors&ust=1613277808145000&usg=AOvVaw3c8JZALLgjMPq6XEt3Z2Ns)‚Äù by Wendell Berry (Chapter 9 in _The Gift of Good Land: Further Essays Cultural & Agricultural_, North Point Press, 1981)
- [Partnership on AI Tenets](https://www.partnershiponai.org/tenets/&sa=D&source=editors&ust=1613277808145000&usg=AOvVaw3jOMuwvofJG6sKj32MZBIc)
- ‚Äú[Of Course Congress Is Clueless About Tech‚ÄîIt Killed Its Tutor](https://www.wired.com/2016/04/office-technology-assessment-congress-clueless-tech-killed-tutor/&sa=D&source=editors&ust=1613277808145000&usg=AOvVaw2VpBS7LxUCtL-AdLCfnpIi)‚Äù (WIRED, 2016)
- ‚Äú[Data Science as Political Action: Grounding Data Science in a Politics of Justice](https://scholar.harvard.edu/files/bgreen/files/data_science_as_political_action.pdf&sa=D&source=editors&ust=1613277808145000&usg=AOvVaw20S4_ycl2N_elmW6uciysm)‚Äù by Ben Green (2019)

</details>

## 10 Feb: Data collection, privacy and digital civil liberties

### Focuses
- Changing norms and laws around privacy across time and cultures, including how people balance privacy vs. other goals
- Data aggregation, matching, and de-anonymization strategies
- Facial recognition technology (used by public and private actors)
- Consent for different types and uses of data

### What is privacy?

- Aristotle: public sphere (politics and commerce üöπ) differs from private sphere (domestic life, family and friends üö∫)
  - Individuals have interests in shielding the public from what happens in private

- Social context is key, regardless of being in public or private
  - We want to be able to control what is known about us + how we present ourselves
  - Privacy is central to individual autonomy or self-determination

- Modern, philosophical defintion of privacy:
  > **The claim of individuals to determine for themselves when, how, and to what extent information about them is shared with or communicated to others**\
  > _Privacy and Freedom_, by Alan F. Westin, Atheneum, 1970, p. 7. 
  - Violations of privacy impose harms
  - Privacy is about protecting intimacy, freedom, and control (Solove, ‚Äú‚ÄòI‚Äôve Got Nothing to Hide‚Äô‚Äù)

#### Privacy harms
Solove, Daniel J. ‚Äú[A Taxonomy of Privacy](https://www.jstor.org/stable/40041279?seq=1).‚Äù University of Pennsylvania Law Review, vol. 154, no. 3, 2006, p. 477.

1. Information collection (surveillance)
2. Information processing (aggregation and inferences from big data)
3. Information dissemination (breach of confidentialty, discloure third parties, blackmail)
4. Invasion of privacy (intrusion, decision interference)

#### Rival values

What other values/rights/interests might be in tension with privacy?

1. National security (terrorism)
2. Public safety (crime)
3. Innovation
4. Convenience

#### Notice and consent

- U.S. approach to a company‚Äôs data: transparency and choice 
- U.S. entities inform individuals and provide a choice to consent or not
- ‚Ä¶This is appealing because 
  1. our idea of privacy is to control information about ourselves
  2. we are committed to the idea of a free market
- But that‚Äôs only true if‚Ä¶
  1. Individuals must be able to make informed, rational choices about the costs and benefits of different privacy policies
  2. The market must be able to deliver a diversity of products with different privacy settings
  3. We must be able to achive the societal balance that we want between privacy and other values via a set of decentralized decisions
- ‚Ä¶Are those true in practice?
- Are individuals today actually up to the challenge of navigating privacy?
  - Social scientists are skeptical (Acquisti 2015). Lawyers are concerned (Solove 2013). Information scientists doubt it (Nissenbaum 2011).
    1. People are uncertain about their preferences
    2. Pereferences are context-dependent
    3. Privacy prefs can be manipulated
    4. Privacy self-management does not scale well
    5. People cannot factor in aggregation
    6. People cannot anticipate harm

#### What are the alternatives?

- Comprehensive privacy regulation
  - ‚Ä¶denies people the freedom to make choices
  - ‚Ä¶is not always clear in the trade off of privacy vs. data use
  - ‚Ä¶limits social benefits to data aggregation
- Improving privacy self-management through:
  - Opt-in > opt-out consent
  - Global > local management
  - Focus on downstream use
  - Acceptability of basic privacy norms

#### Perspectives on data privacy

- Data privacy often involves a balance of competing interests
- Making data available for meaningful analysis
  - for public good: medical research and healthcare improvement, protecting national security
  - for private good: personalized advertising
- Deleting identifiers doesn‚Äôt make PII unidentifiable

### Why do _I_ care about protecting my own privacy?

- I‚Äôm an outspoken woman on the Internet and that comes with a cost. I need to protect myself and my family from any potential abuse.
- I don‚Äôt want to be discriminated against based on criteria I don‚Äôt know about. 
- I‚Äôm going to live for a while ‚Äî I want to be in charge of what information about me exists in the future for myself and my family.
- I want to be able to protest against my country and my government without fear for my safety.
- I don‚Äôt want to be treated differently because of lifestyle choices I intend to keep private.
- I want to be able to make my own decisions without the influence of microtargeting.
- I work for a visible, prominent company, and bad actors could weaponize that against me based on information I intend to keep private.

### Reading list

- Solove, Daniel. ‚Äú[‚ÄòI‚Äôve Got Nothing to Hide‚Äô and Other Misunderstandings of Privacy](https://digital.sandiego.edu/sdlr/vol44/iss4/5/).‚Äù San Diego Law Review, vol. 44, 12 Jul 2007, p. 745.
- Acquisti, Alessandro; Brandimarte, Laura; Loewenstein, George. ‚Äú[Privacy and Human Behavior in the Age of Information](https://science.sciencemag.org/content/347/6221/509.long).‚Äù Science, vol. 347, no. 6221, 30 Jan. 2015, pp. 509‚Äì514. 
- Hill, Kashmir. ‚Äú[The Secretive Company That Might End Privacy as We Know It](https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html).‚Äù _The New York Times_, 18 Jan. 2020. 
- Green, Matthew. ‚Äú[What is Differential Privacy?](https://blog.cryptographyengineering.com/2016/06/15/what-is-differential-privacy/)‚Äù _A Few Thoughts on Cryptographic Engineering_, 15 June 2016.

<details>
  <summary><strong>Supplementary reading</strong></summary>
  
##### Promise and perils

- Sarah Igo, _The Known Citizen_, Introduction, pp. 1-16 (Harvard University Press, 2018)
- Michel Foucault, Discipline and Punish, ch. 3 ‚Äú[Panopticism](https://foucault.info/documents/foucault.disciplineAndPunish.panOpticism/)‚Äù
- [Stanford Administrative Guide, 6.1.1 Privacy and Access to Electronic Information](https://adminguide.stanford.edu/chapter-6/subchapter-1/policy-6-1-1)
- ‚Äú[A Contextual Approach to Privacy Online](https://www.amacad.org/publication/contextual-approach-privacy-online)‚Äù by Helen Nissenbaum (Daedalus 140 (4), Fall 2011)
- ‚Äú[The Class Differential in Privacy Law](https://brooklynworks.brooklaw.edu/blr/vol77/iss4/2/)‚Äù by Michele Estrin Gilman (Brooklyn Law Review, 2012)
- ‚Äú[Limitless Worker Surveillance](https://mronline.org/wp-content/uploads/2017/12/3Ajunwa-Schultz-Crawford-36.pdf)‚Äù by Ifeoma Ajunwa, Kate Crawford, and Jason Schultz (California Law Review, 2016)
- ‚Äú[Facebook and the ‚ÄòDead Body‚Äô Problem](https://www.nytimes.com/2018/04/24/magazine/facebook-and-the-dead-body-problem.html)‚Äù by Gideon Lewis-Kraus (New York Times, 2018)

##### Rights and responsibilities

- Shoshana Zuboff, _The Age of Surveillance Capitalism_, Chapter 18 (PublicAffairs, 2019)
- ‚Äú[Privacy and Information Sharing](http://www.pewresearch.org/wp-content/uploads/sites/9/2016/01/PI_2016.01.14_Privacy-and-Info-Sharing_FINAL.pdf)‚Äù by Lee Rainie and Maeve Duggan, pp. 1-8 (skim the rest), (Pew Research Center, 2016)
- ‚Äú[Americans feel the tensions between privacy and security concerns](http://www.pewresearch.org/fact-tank/2016/02/19/americans-feel-the-tensions-between-privacy-and-security-concerns)‚Äù by Shiva Maniam (Pew Research Center, 2016)
- ‚Äú[Privacy and Data Protection in an International Perspective](https://www.uio.no/studier/emner/jus/jus/JUS5630/v13/undervisningsmateriale/privacy-and-data-protection-in-international-perspective.pdf)‚Äù by Lee A. Bygrave, sections 3-5 (Scandinavian Studies in Law, 2010)
- ‚Äú[Privacy Self-Management and the Consent Dilemma](https://scholarship.law.gwu.edu/cgi/viewcontent.cgi?referer=&httpsredir=1&article=2093&context=faculty_publications)‚Äù by Daniel Solove (Harvard Law Review, 2012)
- ‚Äú[Nudging Privacy: The Behavioral Economics of Personal Information](https://www.heinz.cmu.edu/~acquisti/papers/acquisti-privacy-nudging.pdf)‚Äù by Alessandro Acquisti (IEEE Security & Privacy, 2009)

##### Technical deep dive

- ‚Äú[Private traits and attributes are predictable from digital records of human behavior](https://www.pnas.org/content/110/15/5802)‚Äù by Michal Kosinski, David Stillwell, and Thore Graepel (PNAS, 2013)
- ‚Äú[Differential Privacy: A Primer for a Non-technical Audience](https://privacytools.seas.harvard.edu/files/privacytools/files/differential_privacy_a_primer.pdf)‚Äù by Alexandra Wood et al. (Vanderbilt Journal of Entertainment & Technology Law, 2018), pp. 211-214 (Executive Summary) and pp. 225-246 (Sections III and IV)
- ‚Äú[Why ‚ÄòAnonymous‚Äô Data Sometimes Isn‚Äôt](https://www.wired.com/2007/12/why-anonymous-data-sometimes-isnt)‚Äù by Bruce Schneier (WIRED, December 2007)
- ‚Äú[The Promise of Differential Privacy: A Tutorial on Algorithmic Techniques](https://www.microsoft.com/en-us/research/wp-content/uploads/2011/10/PID2016981.pdf)‚Äù by Cynthia Dwork (Microsoft Research, 2011)

##### Making choices

- ‚Äú[Comparing Privacy Laws: GDPR v. CCPA](https://fpf.org/wp-content/uploads/2018/11/GDPR_CCPA_Comparison-Guide.pdf)‚Äù by DataGuidance and Future of Privacy Forum (2018)
- GDPR, Art. 5 ‚Äú[Principles relating to processing of personal data](https://gdpr-info.eu/art-5-gdpr/)‚Äù
- Eric Glen Weyl and Eric Posner, _Radical Markets_, ch. 5 ‚ÄúData as Labor‚Äù (Princeton University Press, 2018)
- ‚Äú[A Design for Public Trustee and Privacy Protection Regulation](https://scholarship.shu.edu/cgi/viewcontent.cgi?article=1169&context=shlj)‚Äù by Priscilla M. Regan (Stanford Working Paper, 2019)
- ‚Äú[Jaron Lanier Fixes the Internet](https://www.nytimes.com/interactive/2019/09/23/opinion/data-privacy-jaron-lanier.html)‚Äù by Jaron Lanier and Adam Westbrook (video series) (New York Times, 2019)
- ‚Äú[Information Fiduciaries and the First Amendment](https://lawreview.law.ucdavis.edu/issues/49/4/Lecture/49-4_Balkin.pdf)‚Äù by Jack Balkin (UC Davis Law Review, 2016)
- ‚Äú[A Right to Reasonable Inferences: Re-Thinking Data Protection Law in the Age of Big Data and AI](https://journals.library.columbia.edu/index.php/CBLR/article/view/3424)‚Äù by Sandra Wachter and Brent Mittelstadt, pp. 1-18, 78-85 (Columbia Business Law Review, Forthcoming)
- ‚Äú[We May Own Our Data, but Facebook Has a Duty to Protect It](https://www.newyorker.com/tech/annals-of-technology/we-may-own-our-data-but-facebook-has-a-duty-to-protect-it/)‚Äù by Nathan Heller (New Yorker, 2018)
- ‚Äú[State Privacy Legislation Stalls Despite High Hopes](https://www.theinformation.com/articles/state-privacy-legislation-stalls-despite-high-hopes/)‚Äù by Ashley Gold (The Information, 2019)

##### Tensions and trade-offs

- [Stanford Ethics, Technology & Public Policy case study: Facial Recognition](http://ai.stanford.edu/users/sahami/ethicscasestudies/FacialRecognition.pdf)
- ‚Äú[Civil Society Letter to Amazon on Facial Recognition](https://www.hrw.org/news/2019/01/15/letter-amazon-face-surveillance-technology)‚Äù (Human Rights Watch, 2019)
- ‚Äú[The End of Trust](https://www.eff.org/document/end-trust-0)‚Äù from McSweeney‚Äôs and Electronic Frontier Foundation
- ‚Äú[The Perpetual Line-Up: Unregulated Police Face Recognition In America](https://www.perpetuallineup.org/sites/default/files/2016-12/The%20Perpetual%20Line-Up%20-%20Center%20on%20Privacy%20and%20Technology%20at%20Georgetown%20Law%20-%20121616.pdf)‚Äù from Center on Privacy and Technology at Georgetown Law
- Podesta report ‚Äú[Big Data: Seizing Opportunities, Preserving Values](https://obamawhitehouse.archives.gov/sites/default/files/docs/big_data_privacy_report_may_1_2014.pdf)" (especially pp. 58-68)
- "[Report on the Telephone Records Program Conducted under Section 215](https://fas.org/irp/offdocs/pclob-215.pdf)" (Privacy And Civil Liberties Oversight Board, 2014)
- ‚Äú[Facial recognition technology: The need for public regulation and corporate responsibility](https://blogs.microsoft.com/on-the-issues/2018/07/13/facial-recognition-technology-the-need-for-public-regulation-and-corporate-responsibility)‚Äù by Brad Smith (Microsoft, 2018)

</details>

## 17 Feb: Platforms and the public sphere

### Reading list
- Mill, John Stuart. [_All Minus One: John Stuart Mill‚Äôs Ideas on Free Speech, Illustrated_](https://heterodoxacademy.org/library/all-minus-one/). Edited by Richard V. Reeves et al., Heterodox Academy, 2018. 
- Barlow, John Perry. ‚Äú[A Declaration of the Independence of Cyberspace](https://www.eff.org/cyberspace-independence).‚Äù John Perry Barlow Library, Electronic Frontier Foundation, 8 Feb. 1996. 
- ‚Äú[Permanent Suspension of @RealDonaldTrump](https://blog.twitter.com/en_us/topics/company/2020/suspension.html).‚Äù Twitter, Inc., 8 Jan. 2021. 
- Nicas, Jack, and Davey Alba. ‚Äú[Amazon, Apple and Google Cut Off Parler, an App That Drew Trump Supporters](https://www.nytimes.com/2021/01/09/technology/apple-google-parler.html).‚Äù _The New York Times_, 10 Jan. 2021. 

Content moderation is a really hard problem.

 * Obvious to us in tech, but not to ordinary citizens
 * What makes speech valuable? What about technology that changes that? 
 * The rise of private superpowers not beholden to the first amendment: Facebook and Twitter‚Äôs policies on expression is more consequential than France's. 
 * Autonomous review and 
 * There are more options than a binary show/don't show when it comes to content moderation
    * Subject content to fact-checking, warning messages, lower its reach through visibility filtering, user timeouts, etc.



Should Twitter join Facebook's Review Board? Mark shouldn't decide alone, neither should [Jack](https://twitter.com/jack/status/1349510769268850690). 

Does a review board remove accountability from the company itself? Is that a good thing? The review board has a different incentive structure than business needs. The Review Board is an Appeal Court, not a Decision Body. Is public transparency in the board ‚Äî its members, its budget, its process ‚Äî is even more important than what the board does?

Codify "awful but lawful" ‚Äî legal is a very low bar with regard to content moderatin.

What are decisions that courts should make vs. decisions that companies should make?

Whether content exists is different from whether content is seen.

There is an unprecedented level of scope to community standards on social media.

Deplatforming Parler was a deplatforming of a platform. Apple asked Parler to provide a content moderation plan within 24 hours before kicking them off. Will Apple ask that of others? Is Apple a content moderation reviewer?

International human rights standards on incitement differ from existing content moderation policies. And international human rights standards value freedom of expression.

Rules are made on the fly. Decisions and documents left internal, which leads to a lack of public transparency and oversight.

https://www.lawfareblog.com/rushing-judgment-examining-government-mandated-content-moderation

https://podcasts.apple.com/us/podcast/glenn-greenwald-on-substack-content-moderation-joe/id1522960417?i=1000507594869

Will fringe audiences radicalize further as the large forum public spaces online disallow them? 

Salesforce has taken unspecified action to stop the RNC from sending messages from possibly inciting violence. How far up the stack or down the stack should content moderation go? Telecom companies?

In a polarized society, people will look to the individuals with the most power and influence and thus the greatest ability to cause harm and further division.

Political officials that have an incentive to stay in power despite not being democratically elected should be held to the same standard citizens are, without special treatment.

When you can't define the science behind the "art" of moderation, how do you move forward? 
